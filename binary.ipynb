{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import * \n",
    "from sklearn import svm\n",
    "from sklearn import pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# ssize = sample size\n",
    "ssize = 750\n",
    "def convert_file(filename, test=False):\n",
    "  \n",
    "  # load the gdf file\n",
    "  data = mne.io.read_raw_gdf(filename)\n",
    "\n",
    "  # get data in dataframe format\n",
    "  dataframe = data.to_data_frame()\n",
    "\n",
    "  # Get the events \n",
    "  events = mne.events_from_annotations(data)\n",
    "  codes = events[1]\n",
    "  events = events[0]\n",
    "\n",
    "  # last idle sample\n",
    "  idle_size = events[6, 0]\n",
    "  \n",
    "  num_idle_samples = idle_size // ssize\n",
    "  idle_size = num_idle_samples * ssize\n",
    "\n",
    "  # x and y arrays of size 288(actions) + number of idle samples\n",
    "  x = np.ones((288 + num_idle_samples, ssize, 26))\n",
    "  y = np.ones(288 + num_idle_samples)\n",
    "  \n",
    "  \n",
    "  # convert annotations to mne codes\n",
    "  if test:\n",
    "    cfilter = np.asarray(['783'])\n",
    "  else:\n",
    "    cfilter = np.asarray(['769', '770', '771', '772'])\n",
    "  \n",
    "  lis = np.asarray([codes[i] for i in cfilter])\n",
    "  \n",
    "  # # filter for classes\n",
    "  ev = events[np.in1d(events[:, 2], lis)]\n",
    "  \n",
    "  values = dataframe.values#filter(dataframe.values.T, [8, 12], 250).T\n",
    "\n",
    "  for point in range(len(ev)):\n",
    "    x[point] = values[ev[point][0]:ev[point][0] + ssize]\n",
    "    y[point] = 1\n",
    "\n",
    "  index = 288\n",
    "  for i in range(0, idle_size, ssize):\n",
    "    if index == 429:\n",
    "      print(i, idle_size, ssize, num_idle_samples)\n",
    "    x[index] = values[i:i + ssize]\n",
    "    y[index] = 0\n",
    "    index += 1\n",
    "  \n",
    "    \n",
    "  # Create directory for numpy data\n",
    "  if not os.path.exists(\"binary_data\"):\n",
    "    os.mkdir(os.path.join(os.getcwd(), \"binary_data\"))\n",
    "\n",
    "  # get file name without extension or path\n",
    "  new_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "  \n",
    "  # Save data to numpy arrays\n",
    "  np.save(f\"binary_data/{new_name}X\", x)\n",
    "  \n",
    "  np.save(f\"binary_data/{new_name}Y\", y)\n",
    "\n",
    "\n",
    "def convert_data():\n",
    "  if os.path.exists(\"data\"):\n",
    "    datafiles = os.listdir(\"data\")\n",
    "    \n",
    "  else:\n",
    "    print(\"data directory doesn't exist\")\n",
    "    exit(1)\n",
    "\n",
    "  for file in datafiles:\n",
    "    if re.match(r\"A0[0-9]T.gdf\", file):\n",
    "      convert_file(\"data/\" +file)\n",
    "    if re.match(r\"A0[0-9]E.gdf\", file):\n",
    "      convert_file(\"data/\" +file, True)\n",
    "\n",
    "convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shapes are:  (334, 25, 750) (84, 25, 750) (334,) (84,)\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "\n",
    "x = np.load(f\"binary_data/A0{i}TX.npy\")\n",
    "x = x[:, :,1:]\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "y = np.load(f\"binary_data/A0{i}TY.npy\")\n",
    "\n",
    "\n",
    "# x, y = read_file(i)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 100, test_size = 0.2)\n",
    "\n",
    "print(\"final shapes are: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_coeff = featurize(X_train)\n",
    "coeff_len = len(train_coeff)\n",
    "\n",
    "csp = [mne.decoding.CSP(8) for _ in range(coeff_len)]\n",
    "X_train_f = np.concatenate(tuple(csp[x].fit_transform(train_coeff[x], y_train) for x  in range(coeff_len)),axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff = featurize(X_test)\n",
    "X_test_f = np.concatenate(tuple(csp[x].transform(test_coeff[x]) for x  in range(coeff_len)),axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  1.0\n",
      "334\n",
      "test Accuracy is  0.9761904761904762\n",
      "84\n",
      "kappa score on train is:  1.0\n",
      "kappa score on test is:  0.9430508474576271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = pipeline.make_pipeline(StandardScaler(), svm.SVC())\n",
    "clf.fit(X_train_f, y_train)\n",
    "\n",
    "print(\"Accuracy is \", clf.score(X_train_f, y_train))\n",
    "print(len(X_train))\n",
    "\n",
    "print(\"test Accuracy is \", clf.score(X_test_f ,y_test))\n",
    "print(len(X_test))\n",
    "\n",
    "print(\"kappa score on train is: \", cohen_kappa_score(clf.predict(X_train_f), y_train))\n",
    "print(\"kappa score on test is: \", cohen_kappa_score(clf.predict(X_test_f), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31100478468899523\n"
     ]
    }
   ],
   "source": [
    "print(len(y[y==0])/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95        19\n",
      "         1.0       0.98      0.98      0.98        64\n",
      "\n",
      "    accuracy                           0.98        83\n",
      "   macro avg       0.97      0.97      0.97        83\n",
      "weighted avg       0.98      0.98      0.98        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, clf.predict(X_test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5356a0cc24ab421f3fea7505d1e0be20cb885e675eb5d16ff02cf791c65a604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
